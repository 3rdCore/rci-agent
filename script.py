import json
import os
import sys
import pandas as pd
from tqdm import tqdm
import logging
import datetime
from langchain import HuggingFacePipeline

sys.path.append("computergym/")
import main

def load_model(llm):
    """
    Loads the model and the API key from the config.json file.
    """
    with open("config.json") as config_file:
        api_key = json.load(config_file)["api_key"]
    if llm == "chatgpt":
        model = "gpt-3.5-turbo"
    elif llm == "gpt4":
        model = "gpt-4"
    elif llm == "davinci":
        model = "text-davinci-003"
    elif llm == "ada":
        model = "ada"
    elif llm == "babbage":
        model = "babbage"
    elif llm == "curie":
        model = "curie"
    elif llm == "davinci1":
        model = "davinci"
    elif llm == "davinci2":
        model = "text-davinci-002"
    elif llm == "starcoder":
        model = "HuggingFaceH4/starchat-beta"
    else:
        raise NotImplementedError("This method has not been implemented yet")    
    return api_key, model

def create_opt(models, task_names):
    opt = main.parse_opt()
    opt.llm = None
    opt.env = None
    opt.num_episodes = 10
    opt.step = -1  # -1 means use the plan step generated by the llm
    opt.erci = 1
    opt.irci = 3
    opt.prompt_token_price = 0.03       #0.002
    opt.completion_token_price = 0.06   #0.002
    opt.sgrounding = True
    opt.headless = True

    # adding new fields to the opt object
    setattr(opt, "models", models)
    setattr(opt, "task_names copy", task_names)

    name = "sanity_check_starcoder"
    current_date = datetime.date.today().strftime("%m_%d")
    results_dir = f"/mnt/ui_copilot/results/RCI/{current_date}_benchmark_test_multi_gpu/"    
    setattr(opt, "results_dir", results_dir)
    setattr(opt, "name", name)

    # storing all the hyper-parameters and settings in a json file
    with open("arguments.json", "w") as f:
        json.dump(vars(opt), f)

    return opt


def save_model_results(df, model, name="", path=""):
    df_model = df.loc[df["model name"] == model]
    df_model = df_model.drop("model name", axis=1)

    filename = "results_" + model + "_" + name + ".xlsx"
    os.makedirs(path, exist_ok=True)

    file_path = os.path.join(path, filename)
    if os.path.exists(file_path):
        os.remove(file_path)
    df_model.to_excel(file_path, index=False)

    filename = "results_" + model + "_" + name + ".json"
    file_path = os.path.join(path, filename)
    if os.path.exists(file_path):
        os.remove(file_path)
    df_model.to_json(file_path)


# manual AZERTY/QWERTY prevention
# print("Please press the 'A' key on your keyboard:")
# user_input = input()

# reading the models and tasks from the json files
model_filename = "model_names.json"
tasks_filename = "task_names.json"


with open(model_filename) as f:
    models = json.load(f)["model_name"]
with open(tasks_filename) as f:
    task_names = json.load(f)["task_name"]

# creating the opt object
opt = create_opt(models, task_names)

if os.path.exists("error_logs.txt"):
    os.remove("error_logs.txt")

columns = [
    "model name",
    "task_name",
    "success_rate",
    "min tokens sent",
    "max tokens sent",
    "avg tokens sent",
    "min tokens received",
    "max tokens received",
    "avg tokens received",
    "n LLM calls",
    "time",
    "estimated cost",
    "experiment folder",
]
df = pd.DataFrame(columns=columns)

budget = 100  # budget in USD
remaining_budget = budget
flag = False



params = {"temperature": 0, "max_tokens": 256}
open_ai_params = {
"top_p": 1,
"frequency_penalty": 0.0,
"presence_penalty": 0.0,
}



# running the main loop
for model in tqdm(models, desc="Models") if not flag else []:
    print("Using model : ", model)
    opt.llm = model  # switch model
    api_key, model_name = load_model(opt.llm)

    if opt.llm  == "starcoder":
        lang_model = HuggingFacePipeline.from_model_id(
        model_id="HuggingFaceH4/starchat-beta",
        task="text-generation",
        model_kwargs={"temperature": 0, "max_length": 256, "device_map" : "auto"}
        )
    else:
        lang_model = ChatOpenAI(
        model_name=model_name,
        **params,
        model_kwargs=open_ai_params,
        openai_api_key= api_key,
        )
    setattr(opt, "lang_model", lang_model)

    for task_name in tqdm(task_names, desc="Tasks", leave=False) if not flag else []:
        opt.env = task_name  # switch task
        print("     Task addressed : ", opt.env, "\n")
        try:
            if remaining_budget <= 0:
                flag = True
                raise Exception("Budget exhausted")
            result = main.miniwob(opt)  # running benchmark
            # storing the latest results in the dataframe
            df.loc[len(df)] = [
                model,
                task_name,
                result["success_rate"],
                result["min_sent"],
                result["max_sent"],
                result["mean_sent"],
                result["min_received"],
                result["max_received"],
                result["mean_received"],
                result["mean_calls"],
                result["time"],
                result["cost"],
                result["experiment folder"],
            ]
            # updating the budget
            remaining_budget -= result["cost"]

        except Exception as e:
            with open("error_logs.txt", "a") as f:
                f.write("error in the task : " + task_name + " , exception : " + str(e) + "\n")

            df.loc[len(df)] = [model, task_name, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, "error"]

        save_model_results(
            df, model, opt.name, opt.results_dir
        )  # saving the results of the model in a json and excel file

logging.info("total cost : " + str(budget - remaining_budget))
